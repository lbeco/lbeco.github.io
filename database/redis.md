

# redis

### redis持久化

aof：append only file 持久化的日志文件

rdb：redis文件的快照

以bg形式fork一个线程来生成



### 数据类型：

string 		key value存储string

hash			存储一个kv的hashmap

list 			链表 可以做栈或者队列 底层结构：双向链表

set			集合

sorted set（zset）有序集合类型使用**跳表**

跳表 https://blog.csdn.net/weixin_45480785/article/details/116293416

hyperloglog 基数统计

bitmap 位图 可以用来做布隆过滤器

GEO 地理位置 计算距离 指定范围内点等 使用geo hash进行编码







事务：需要watch来关注相关数值，watch中数值发生变化就会进行回滚

代码写错了不作回滚

事务没啥人用，太垃圾了

一个名叫过期字典的数据库保存过期时间



## redis删除多余数据

Redis的内存回收机制主要体现在以下两个方面：

- 删除到达过期时间的键对象。
- 内存使用达到`maxmemory`上限时触发内存溢出控制策略。

### 过期删除策略

定时删除 ：在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。

惰性删除： 当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。

定期删除 ：周期性抽查存储空间 

​	**优点**：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。

​	**缺点**：难以确定删除操作执行的时长和频率。

* 如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。
* 如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。
* 另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误

**redis的做法**

同时使用了定期删除和惰性删除

原文链接：https://blog.csdn.net/m0_38017860/article/details/124325088

每秒钟执行server.hz次serverCron

​										databasesCron 数据库轮询

​										activeExpireCycle expires轮询 随机挑选W个key。如果一轮中删除的key超过25%，循环该过程，否则检查下一个expires

### 内存淘汰机制

数据逐出：满了就删除 使用lru/lfu 等算法

几个例子：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（**这个是最常用的**）

## redis多机

哨兵模式：Sentinel节点监控redis集群中Master主服务器工作的状态，一个redis对应一个哨兵

主观下线：对单个redis节点的心跳没有回复

客观下线：哨兵节点共同判断下线

leader选举：类似raft

假设主服务器宕机，哨兵1先检测到结果，但是系统并不会马上进行failover过程，仅仅是哨兵1主观认为主服务器不可以用，这个现象称为主观下线，当后面的哨兵也检测到主服务器不可用，并且数量达到一定时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover故障转移操作。
操作转移成功后。就会发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这一过程称为  客观下线

4.0:混合持久机制

6.0引入多线程

Redis6.0 引入多线程主要是为了提高网络 IO 读写性能







### 几大问题

**雪崩**：较短时间内较多key**集中过期**，请求大量积压，导致数据库被打爆，于是redis超时，最后崩溃

解决：预警 页面静态化 多级缓存 限流降级 有效期错峰加随机值 超热数据永久持久化

**击穿**：**单个**key非常热，过期后击穿 

解决：预先设定或现场将过热数据改为永久key，高峰来临时刷新数据有效期；设置二级缓存，保障两个缓存不会同时被淘汰

**穿透**：redis内存正常实命中率随时间下降，数据库压力大，崩掉。原因：出现大量**非正常**url访问，导致去数据库中查找

解决：布隆过滤器，实时监控后黑名单防控 

监控：prometheus cloud insight redis



## redis分布式锁

分布式锁：setnx（set if not exist）添加 需要考虑过期时间

示例：set name liuxinglin ex 100 nx

### redisson

redisson是用java实现的redis分布式可重入锁

https://segmentfault.com/a/1190000038988087

防止redis单点故障，引入redlock，redlock可以保证大多数redis服务同意获取的锁，从而实现分布式



### RedLock

redlock不需要节点之间的复制，，假设有5个redis节点，客户端取锁流程会变成这样：

- 以毫秒为单位获取当前的服务器时间
- 尝试使用相同的key和随机值来获取锁，客户端对每一个机器获取锁时都应该有一个超时时间，比如锁的过期时间为10s，那么获取单个节点锁的超时时间就应该为5到50毫秒左右，这样做的目的是为了保证客户端与故障的机器连接不耗费多余的时间！超时间时间内未获取数据就放弃该节点，从而去下一个Redis节点获取。
- 获取完成后，获取当前时间减去步骤一获取的时间，当且仅当客户端从半数以上(这里是3个节点)的Redis节点获取到锁且获取锁的时间小于锁额超时时间，则证明该锁生效！
- 如果取到了锁，**key的真正有效时间等于有效时间减去获取锁所使用的时间**（步骤3计算的结果）。
- 如果获取锁的机器不满足半数以上，或者锁的超时时间计算完毕后为负数等异常操作，则系统会尝试解锁所有实例，即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁

RedLock不能提供可靠的服务

## **延时双删**

一般我们在更新数据库数据时，需要同步redis中缓存的数据
所以存在两种方法：
（1）第一种方案：先执行update操作，再执行缓存清除。
（2）第二种方案：先执行缓存清除，再执行update操作。

弊端:当存在并发请求时，很容易出现问题
（1）第一种方案：当请求1执行update操作后，还未来得及进行缓存清除，此时请求2查询到并使用了redis中的旧数据。
（2）第二种方案：当请求1执行清除缓存后，还未进行update操作，此时请求2进行查询到了旧数据并写入了redis。



所以：**先进行缓存清除，再执行update，最后（延迟N秒）再执行缓存清除。**

延迟N秒的时间要大于一次写redis操作的时间。这样做保证了一致性。以下图为例，线程2写入后被线程1删除。

![image_5.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bee4d1f2036e48d7926d6a299c9959c0~tplv-k3u1fbpfcp-watermark.image?)
